{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT CHECK THE MODEL NAME\n",
    "new_model_name = 'model_50K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = joblib.load('data/' + new_model_name + '/train.pkl')\n",
    "test = joblib.load('data/' + new_model_name + '/test.pkl')\n",
    "eng_tokenizer = joblib.load('data/' + new_model_name + '/eng_tokenizer.pkl')\n",
    "eng_length = joblib.load('data/' + new_model_name + '/eng_length.pkl')\n",
    "eng_vocab_size = len(eng_tokenizer.word_counts) + 1\n",
    "targ_tokenizer = joblib.load('data/' + new_model_name + '/targ_tokenizer.pkl')\n",
    "targ_length = joblib.load('data/' + new_model_name + '/targ_length.pkl')\n",
    "targ_vocab_size = len(targ_tokenizer.word_counts) + 1\n",
    "trainX = joblib.load('data/' + new_model_name + '/trainX.pkl')\n",
    "testX = joblib.load('data/' + new_model_name + '/testX.pkl')\n",
    "model = load_model('data/' + new_model_name + '/' + new_model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = targ_tokenizer.texts_to_sequences(train[:,1])\n",
    "trainY = pad_sequences(trainY, maxlen=targ_length, padding='post')\n",
    "trainY = to_categorical(trainY, num_classes=targ_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = targ_tokenizer.texts_to_sequences(test[:,1])\n",
    "testY = pad_sequences(testY, maxlen=targ_length, padding='post')\n",
    "testY = to_categorical(testY, num_classes=targ_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(new_model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, epochs=1, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
